{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from melbanks import LogMelFilterBanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load example audio file from torchaudio\n",
    "sample_speech, sr = torchaudio.load(torchaudio.utils.download_asset(\"tutorial-assets/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav\"))\n",
    "# Resample to 16kHz if needed\n",
    "if sr != 16000:\n",
    "    resampler = torchaudio.transforms.Resample(sr, 16000)\n",
    "    sample_speech = resampler(sample_speech)\n",
    "    sr = 16000\n",
    "\n",
    "# Parameters for both implementations\n",
    "params = {\n",
    "    'n_fft': 400,\n",
    "    'hop_length': 160,\n",
    "    'n_mels': 80,\n",
    "    'power': 2.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_melspec = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate=sr,\n",
    "    **params\n",
    ")\n",
    "\n",
    "custom_melspec = LogMelFilterBanks(\n",
    "    samplerate=sr,\n",
    "    **params\n",
    ")\n",
    "\n",
    "torch_output = torch.log(torch_melspec(sample_speech) + 1e-6)  # Add log for comparison\n",
    "custom_output = custom_melspec(sample_speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch_output.shape == custom_output.shape\n",
    "assert torch.allclose(torch_output, custom_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(12, 12))\n",
    "\n",
    "im1 = ax1.imshow(torch_output[0].numpy(), aspect='auto', origin='lower')\n",
    "ax1.set_title('Torchaudio Implementation')\n",
    "ax1.set_ylabel('Mel Frequency Bin')\n",
    "plt.colorbar(im1, ax=ax1)\n",
    "\n",
    "im2 = ax2.imshow(custom_output[0].numpy(), aspect='auto', origin='lower')\n",
    "ax2.set_title('Custom Implementation')\n",
    "ax2.set_ylabel('Mel Frequency Bin')\n",
    "plt.colorbar(im2, ax=ax2)\n",
    "\n",
    "difference = torch_output[0] - custom_output[0]\n",
    "im3 = ax3.imshow(difference.numpy(), aspect='auto', origin='lower')\n",
    "ax3.set_title('Difference (Torchaudio - Custom)')\n",
    "ax3.set_ylabel('Mel Frequency Bin')\n",
    "ax3.set_xlabel('Time Frame')\n",
    "plt.colorbar(im3, ax=ax3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
